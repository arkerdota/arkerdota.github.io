---
title: 大数据专业练级指南
date: 2024-01-04 13:59:52
tags: 大数据
toc: true
comments: true
---

这个是针对学校的城市学院学生学习规划（一生一梦想、一生一规划），写的一个大数据专业的练级指南。

 设备选择：笔记本需要16G内存（32G更好），SSD 1T以上，其实什么样的设备都能搞学习，这个方面不重要，只是我们后期搞集群开的虚拟机较多的情况下，多点内存比较流畅（现在基本用云环境，也不差多少）

 

## 学习路线的规划：

### 大一阶段：

程序语言基础+算法+数据结构，我认为是要在大一阶段就要搞定的，要求的话是 Java语言（吃饭的家伙），python语言（随手解决一些问题+数据分析使用）都要会，一开始可以随便挑一种练。如果刷题走比赛路线ACM,ICPC，蓝桥杯 可以适当学一下C++（岗位较少不推荐）。

学习的方法是刷题为主，这个阶段可以广泛的在B站，油管上面看一些计算机专业的课程，看一下名校的计算机专业课是怎么上的，讲的内容是哪些，同时也可以关注一下科技资讯类新闻，了解一下产业方向，对行业有一定的了解（有了了解才会有兴趣，有兴趣才会有工作）。

看一些入门级别专业书，背景介绍类的吴军老师的《浪潮之巅》《大学之路》等，吴军老师写书是一把好手，深入浅出，寓教于乐。思维拓展的万维钢《[万万没想到：用理工科思维理解世界](https://baike.baidu.com/item/万万没想到：用理工科思维理解世界/16171130)》,《[智识分子：做个复杂的现代人](https://baike.baidu.com/item/智识分子：做个复杂的现代人/19501337)》，计算机行业经典图书《代码大全》《人月神话》《重构——改善既有代码的设计》《代码整洁之道——程序员的职业素养》《敏捷软件开发——原则、模式与实践》《黑客与画家》，这里每一本我都读过，也介绍给大家，基本上有了行业基本 了解之后，对后期的学习也会大有裨益。

（PTA乙级挑战不要忘了, AC70题送U盘一个，拿下PTA顶级证书（几百家公司学校免笔试机试），送华为小镇半价门票一张）

 

### 大二阶段：

这个阶段除了学院的课程学习，其实开始要做项目，如果完成一个好的项目出来，比如说你要做个网站，开发一个系统，那么就一定要学会一门前端语言，前端是个更新非常快的领域，同时轮子（各种组件，模板）也特别多，学习难度不大，但是学习的东西特别多，建议就是要用的时候再学，不求全部学会，只求会用。以后工作中有很多知识都是临时学的，要有快速学习能力，1个星期就能出活。 

根据自己的生活或者思考结合自己已有的知识，开始做自己的系统，这里一定要说一下，不要选择过于老旧的技术栈，想想看3年毕业后找工作，这技术都过时到哪里去了，所以说不要图一时之简单（这里要吐槽一下还在用VC写代码的同学），用现代编辑器，Java就用IDEA，python就用Pycharm，前端就用Vscode。我不是说他们有多优秀，大家可以先看看新的东西是如何设计的（同时可以接入人工智能插件，比如copilot,codota,aixcoder等等），新的技术chatgpt也要用起来（平替也可以），总之不要在这里花钱，或者花少量的钱一两百搞定这些。

项目可以用现成的模板改，中间可以不断的增加对应功能，有问题可以多方查找资料，一定要是能够解决现实环境的问题（首先一点自己要愿意用），你首先是你自己系统的头号用户。

不建议从头开始造轮子，又累又辛苦又慢，挫败感很强，只是感动了自己。

这时候可以用项目参加一下“互联网+”大赛，程序设计大赛，“双创”大赛，一定要大二开始投，因为第一年肯定是陪跑的，根据反馈意见优化系统，大三再冲刺奖项。

这时候看的书以专业书为准，建议的话，根据需求来找专业书，怎么找靠谱的呢，机械工业出版社出版的黑皮书系列，人民邮电出版社出版的异构图书，图灵图书。日本人写的一些入门类书籍很不错，当然还有《大话设计模式》《大话数据结构》《鸟哥的linux私房菜》这类国产优秀图书。

 

### 大三阶段：

实习！一定要去找企业实习，大二的暑假，大三的暑假是你们最好找到实习工作的地方，大二可以不用考虑公司，只要是计算机专业的都行，大三就要去看看能不能进心仪的企业。这个时候应该开发你的第二个项目了，你现在大概对技术和商业都有了自己的了解。也有一定的成熟经验了，可以开发真正针对市场需求的项目了。这里开始有细分专业的分支了。毕竟我们是大数据专业，一定要体现出大数据的内容。这里稍微介绍一下技术栈，这里每一个加黑字体都是一个对应的方向，大家酌情看一下。

 

## **Hadoop**技术栈：

主要以Hadoop稳定版本为基础，包括：HBASE、Hive、Zookeeper、Sqoop等组件重点讲解：

1. 环境部署：Hadoop完全分布式的环境配置与搭建（实验用三节点）、Hadoop HA高可用环境部署（生产型）、主备节点的同步与自动切换、Zookeeper组件配置与使用。

 

2. 数据处理：HDFS分布式存储的常用命令（文件上传、下载、查看、统计等）、基于Java/Python代码实现对HDFS的运维操作（文件上传、下载、统计）；

 

3. Hadoop数据处理原理与机制（MapReduce框架）、MapReduce的sort&shuffle（实现排序、二次排序、数据去重、最高销量统计等），完成文件压缩、分布式数据复制、记录行级别的数据验证等场景；

 

4. Yarn资源调度原理与机制，理解Yarn框架在多个大数据架构中的实际应用。

 

5. Hadoop 数据建模：目前Hadoop作为大数据整个技术架构中的基座技术，更多的承担起数据的分布式存储、传统数据仓库迁移其上，实现海量数据的查询等操作。首先考虑Hadoop应用的架构设计

 

6. 数据存储选型，主要根据基于Hadoop的应用存储类型来决定，选择标准文件格式、序列化存储、列式存储等 。

 

7. HDFS模型设计。理解HDFS存储中文件的位置、如何对数据进行分区、分桶以及反向规范化。

 

8. HBASE模型设计。HBASE的分布式部署，列式存储与传统行式存储的区别、行键、时间戳，表和region以及如何使用列。

 

9. 元数据管理。Hive的部署，什么是元数据，元数据在Hadoop中存储位置，使用Hive进行元数据管理，Hive的常用数据查询操作。

 

10. 数据采集。理解数据采集的更新方式（全量、增量）以及访问模式，数据采集工具Sqoop的部署，使用Sqoop实现Hadoop与传统数据库的批量数据传输。

 

## **Spark**技术栈：

主要以Spark 稳定版本为基础，包括：Scala、Flume、Kafka、MongoDB等组件重点讲解

 

1. RDD 弹性分布式数据集。RDD的创建、作用域，如何进行转换（map、filter、distinct等），RDD操作计划任务（take、collect、reduce等）

 

2. DataFrame。创建DataFrame、DataFrame查询以及如何利用SQL完成查询。

 

3. Spark SQL与数据分析。Spark SQL 运行原理与机制，使用DataFrame实现Spark SQL查询，利用Spark SQL完成日常运营数据分析。

 

4. Spark Streaming 流式计算。掌握Spark Streaming基础概念和运行原理，理解Spark Streaming中DStream的两类操作、容错处理机制等。

 

5. Spark MLlib机器学习。了解什么是机器学习及在大数据中的具体应用。MLlib库的基本介绍，基于MLlib场景学习（预测婴儿生存率）及模型调优的实例学习。

 

6. Kafka消息分布式系统。实现Kafka与Spark Streaming的整合部署，实现实时数据处理功能。

 

7. Flume 日志采集工具。Flume的部署，整合kafka实现数据的统计分析。

 

8. MongoDB数据库。MongoDB数据库的安装与部署，使用PySpark向MongoDB推送数据，在MongoDB中查询数据。

 

### **数据清洗与处理**

 

1. Pandas 数据结构：series与DataFrame，使用Pandas对数据的读取（CSV与JSON），使用Pandas进行数据清洗。

 

2. Numpy 数组对象、数据类型，创建数组、数组切片与索引操作，数组常见操作，Numpy函数（字符串函数、数学函数、算术函数、统计函数、排序函数等）

 

3. ETL工具使用。重点以KETTLE为基础，讲解kettle工具的基本配置、转化流程常见组件（输入组件、输出组件、转化组件）、kettle数据库连接与资源库配置、脚本组件、大数据平台对接等内容。

 

### 数据可视化

 

1. Excel商业可视化分析基础。学习数据可视化相关概念与分类，可视化展现原则，Excel公式与函数，常见图表设计与实现，数据处理与加工（数据分组、转换、分类、重组等），数据排序与筛选，透视表与分析

 

2. Python可视化组件。Matplatlib/seaborn可视化组件的基本使用，绘图函数，常见图形的实现。

 

3. 数据可视化工具。Tableau/Power BI的工具使用，数据源创建，数据调用与展现等。

 

### **容器与K8S构建大数据系统**

 

Docker安装与运行，了解Docker容器化与虚拟化的不同，掌握Docker核心组件（镜像、容器、仓库）相关基本操作。

 

Docker镜像与容器。理解Docker中镜像与容器的关系，掌握对容器的日常管理和操作。

 

Docker数据管理。实现基于Docker的数据存储和管理。掌握数据卷的使用以及应用场景。

 

Docker网络与通信。实现自定义Docker容器的网络配置，能够基于多个容器构建分布式应用系统。

 

Kubernetes部署。掌握Kubernetes架构及核心概念，实现Kubernetes的分布式部署。

 

调度单元Pod。理解Pod组成原理及生命周期，掌握相关事件处理的方式，实现以Pod方式运行在Kubernetes上。

 

网络实现。实现从外部网络访问Pod运行的资源，利用Service和ingrees实现资源的调用。

 

控制器。理解和掌握对Pod的生命周期的管理，了解Pod如何被调度。

 

持久化存储数据。在Kubernetes中实现数据的持久化存储，使用持久化卷、存储类等实现持久化场景。

 

Kubernetes应用部署。实现应用部署，完成空间隔离和镜像升级。并对相关平台资源进行监控。

 

这几个方向我是从网上抄的，大致不差，有些细节可能没有更新。

那么肯定有同学会问，学的完么？不学完会不会找不到工作。

就我个人经验来看，不用学完，但是一定要有这个技术概念在心里面，然后从自己的项目中间去学习对应的技术，比如你消息系统用了kafka，那么你肯定要对kafka的消息传递机制，集群搭建和选举规则都要了解。比如你可视化用了pycharts，那么那些图片的实现，也一定要了如指掌。实事求是，从自己的项目学习，记得是非常牢靠的，如果仅限于背面经，那么面试的时候很容易被拆穿。

 

### 大四阶段：

实际上的大四阶段，只有1个学期，这个时候你会有大量的杂事，（实习，论文，秋招，春招，毕业事项）打乱你的学习过程，所以千万不要在这里亡羊补牢，如果按照上面的准备，这个时候你已经在一家公司以准员工的身份在工作了。如果荒废了前三年，那么很多同学会问老师要不要报名培训班。我已经给大家说过了，1、培训班讲的，我们专业课上都讲过，没讲过得在项目训练或者公开资料上都能查到，2、培训班有没有效果，有的，大几万砸下去的愧疚感+找不到工作的社会打击力度，会让很多同学幡然悔悟努力学习，3、坏处也有，培训班为了你的就业，会给你简历造假，简历造假被发现一般就是开除（有些资深面试官很容易看出造假，而且开除还不用赔偿也无法劳动仲裁）。你会一直提心吊胆的生活。

好的工作哪里来 内推>官网>各类人才网站。多在行业论坛与人交流，看看行业的需求，以及热点的技术在哪里，针对性的学习。

 

Q&A 人工智能要不要学

建议是考研之后再去学

Q&A 考公建不建议

建议是家里有矿去考，没有的话还是要靠一技傍身。

如果还有其他问题可以在企业微信上问我，我找时间更新一下文章。

 

PS：既然是练级指南，还有独门秘籍要说一下

1、 本专业圣经《数据密集型应用系统设计》《凤凰架构:构建可靠的大型分布式系统》，常看常新，写的非常好，吹水聊天之必备。

2、 写博客，之前上课已经要求过了，博客是一种总结，也是构建自己的影响力手段，同时也是人生另外一种的可能性，别人也可以很快的了解你。
